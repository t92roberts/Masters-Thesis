% Chapter Template

\chapter{Background}\label{ChapterBackground}

This chapter gives an overview of the two important themes of this thesis: agile software development and optimisation problems. It will establish the vocabulary used throughout the rest of the paper and outline the concepts about these two topics that will give some context to the implementation and results of the work.

\section{Agile Software Development}

When writing software became less of an academic exercise and more of a commercial one, there were few frameworks available for how to manage this process. \citet{benington1983production} is cited as one of the first to suggest an approach to developing large programs inspired by the highly-structured processes used in manufacturing. It consisted of a nine stage plan that maps out the phases of a project, starting with creating a list of requirements for what the system needs to do, implementation, testing and end-user evaluation. \citet{royce1987managing} was one of the first to formalise this process and it would later become known as the Waterfall Model (notice that Royce used this model as an example of a bad way to develop software that should be avoided). Since then, many frameworks have been proposed as an alternative to waterfall that try to deliver software products on time, within budget, but most importantly, that meets the customer's expectations.

Agile software development is one such approach that has been widely adopted by development teams. Agile is the term for a collection of frameworks based on the values described in the Manifesto for Agile Software Development (\citet{beck2001manifesto}). Agile methodologies focus not only on how to organise and manage the technical work required to deliver a product, but also how to foster cohesion and collaboration both within the development team and in the organisation. Broadly, Agile methodologies aim to increase the quality of software deliveries by putting great emphasis on building and maintaining a well-functioning team that is able to deliver the functionality that the customer values the most. Empirical studies such as \citet{dybaa2008empirical} have shown that depending on the size and maturity of the development team (and the company), it can sometimes be difficult to adopt the process. However once it is adopted, it is generally seen as a positive step in managing the software development process. In particular, the human and social factors that the principles foster can create a team that is more relaxed and collaborative.

%give a summary of Scrum and the development cycle (use diagrams)

A central part of Agile is the idea of working in \emph{sprints} -- short periods of time where the development team works on tasks (known as \emph{user stories}) that deliver the most value to the customer at that moment in time. A sprint typically lasts 1 or 2 weeks but can be much shorter. Working to these very short time horizons instead of long project cycles means that if the customer's priorities change during a project, unforeseen problems occur, or entirely new requirements are added, the agile development team is able to shift focus after every sprint to accommodate this. The main roles in an agile team are the \emph{Product Owner}, the \emph{Development Team}, and the \emph{Scrum Master}.

The Product Owner may either be the customer themselves or a representative for a group of customers. They are responsible for digesting the sometimes conflicting needs of the customers and maintaining a \emph{Product Backlog} that acts as a wish list of functionality that the customers want in the product. Any item in the backlog has a chance (but not a certainty) of being implemented, and anything not in the backlog will not be implemented. Every item is given a \emph{business value} which is a relative value of importance, and the Product Owner is responsible for ensuring that the most important tasks are given top priority. They are also responsible for writing user stories that the Development Team can understand so that it is easy for them to implement and test. A clear 'Definition of Done' is essential so that the Product Owner and Development Team can agree when a user story has been delivered successfully.

The Development Team is responsible for carrying out the technical work to deliver working software. They are empowered to estimate how much effort it will take to implement each task in the Product Backlog. There has been much debate and advice about how to effectively estimate the effort of user stories \citep{cohn2004user} and the measure used in this thesis is \emph{story points}. Every agile team is free to define their own scale of story points but typically they are not equivalent to elapsed time. Instead, they indicate a combination of how difficult, uncertain, and large a task is. The team can use techniques such as Planning Poker \citep{cohn_planning_poker} to make realistic estimates that everyone agrees on. Together with the Product Owner, the Development Team may also add more user stories to the backlog, for example, if a user story is dependent on some other work to be finished before it can be started on. If a user story is judged to be too large to fit into one sprint, they can work with the Product Owner to redefine the scope of the Definition of Done and break it down into multiple smaller stories that can each be delivered within a sprint. The Development Team is also responsible for communicating their planned vacation and allocation during a sprint so that the team can plan its work.

The Scrum Master is responsible for encouraging all members of the team to work in line with the principles of the Agile Manifesto and generally try to ensure that the Development Team runs efficiently and is able to deliver what the Product Owner is asking for. They work to remove any obstacles or problems blocking the Development Team from working on the tasks they have committed to. Before a sprint starts, the team holds a sprint planning meeting where they decide on which user stories will be taken in to the coming sprint. When planning the upcoming sprint, the plan should strike a good balance between delivering high-value user stories and not overloading the Development Team. The Product Owner refines the business value estimations, the Development Team refines the story point estimations, and the Scrum Master facilitates both parties to agree on a realistic and valuable sprint plan.

\section{Combinatorial Optimisation Problems}

Combinatorial Optimisation (CO) is an area of computer science where a problem is modelled in a way that a solution can be expressed as a set of assignments of values to variables. An objective function can then take a solution as an input and return a value that indicates how good the solution is. The goal is to search the set of all possible solutions to find the optimal set of assignments that maximises or minimises the objective function (depending on what is desirable for a particular problem). Notable examples of CO problems are the Travelling Salesman Problem (TSP), the Quadratic Assignment Problem (QAP), and the Resource-Constrained Project Scheduling Problem (RCPSP). Because many real-world problems can be modelled as a CO problem, there has been much research into how to solve them. Two broad classes of approaches have emerged: complete algorithms and approximation algorithms.

\subsection{Complete Algorithms}
\label{subsec:complete_algorithms}

The set of all possible solutions to a CO problem is typically finite, so an algorithm that can exhaustively search every possible solution is guaranteed to find the optimal one. A problem is modelled by defining an initial empty state, a function to get the set of actions for a given state, a function that applies an action to a state, and a test to check if the goal has been reached. Therefore, a solution is represented as a sequence of actions performed in a given order to get from the initial state to the goal state \citep{russell2016artificial}. However, CO problems that are NP-hard \citep{garey1979computers} may take an exponentially-increasing time to solve which is impractical in most real problems. The Branch and Bound (B\&B) algorithm \citep{land1960automatic} is the most widely-used tool for solving large-scale NP-hard combinatorial optimisation problems \citep{clausen1999branch}. It solves integer programming problems by performing an LP relaxation of an IP problem. This relaxes the requirement that the decision variables must be given an integer value and instead allows them to be given a continuous value. "The state-space graph of the relaxed problem is a \emph{supergraph} of the original state space because the removal of restrictions creates added edges in the graph. Because the relaxed problem adds edges to the state space, any optimal solution in the original problem is, by definition, also a solution in the relaxed problem; but the relaxed problem may have better solutions if the added edges provide short cuts. Hence, the cost of an optimal solution to a relaxed problem is an admissible heuristic for the original problem" \citep{russell2016artificial}. Since the LP relaxation is less restrictive than the IP problem, there are potentially more feasible solutions to be found. The intuition is that a feasible solution to the LP relaxation that happens to contain only integer values is also a feasible solution to the original IP problem.

Branch and Bound manages a search tree where a node represents an LP sub-problem of the original LP relaxation and each node is solved using a linear programming algorithm like the simplex method \citep{dantzig1949programming}. If a solution contains any continuous values, new nodes are branched. Each branch contains a sub-problem of its parent but with an additional constraint on one of the variables that was continuous. For example, if decision variable $d_1 = f$ and $f$ is a continuous value, two nodes are branched: the first branch adds the constraint that $d_1 \leq \floor*{f}$ and the second branch adds the constraint that $d_1 \geq \ceil*{f}$. These two sub-problems are solved and branched in the same way (if needed) and the process is repeated until an integer solution is found or the full state space has been explored. The value of the objective function of an integer solution is compared to the current best bound and if it is better, the bound is updated. If it is worse than the best bound, the branch is cut and is not expanded any further (it is also cut if the sub-problem is found to be infeasible). If a bound found early in the search is close to optimal, many branches can be cut and the area of the state space explored is greatly reduced. In the worst case, the order in that integer solutions are found only improves the bound slightly each time and it remains far from optimal throughout the whole search. Therefore, no/few cuts are made and the search degenerates to an exhaustive search.

\section{Approximation Algorithms}
In classical search (as described above), the state space is systematically explored by recording the path taken from the start to a state that is a feasible solution. However, many real-world problems only require the solution and the path used to build it is irrelevant. Similarly, many applications do not require the optimal solution and a solution that is 'good' (i.e. close to optimal) is sufficient. By relaxing these requirements, local search algorithms can be used \citep{russell2016artificial}. Local search algorithms maintain a single 'current' node (and a set of its neighbours) making it a very lightweight approach compared to classical search that can often find reasonable solutions to problems with large state spaces in much less time.

Constructive algorithms start with an empty or partial solution and try to make assignments until a good solution is found. These can run very fast but often give poor results compared to local search algorithms \citep{blum2003metaheuristics}. Local search algorithms start with a complete solution and try to modify some of its assignments to improve the value of the solution. Making small changes to a solution to create new but similar solutions is known as generating its \emph{neighbourhood}. A local search algorithm explores a solution's neighbourhood by generating its neighbours, comparing their values, and selecting the best neighbour to accept as the new 'current' solution. Ideally, this process can be repeated and the search follows a path of increasingly-valuable solutions until it reaches the global optimum. Local search has the additional benefit that it does not need to maintain a search tree and only one solution needs to be stored in memory, making it very memory-efficient.

As described in \citet{ahuja2002survey}, a neighbourhood search algorithm can be defined as: (1) a neighbourhood graph where a node represents a feasible solution and a directed arc $(S,T)$ indicates that $T$ is in the neighbourhood of $S$, (2) a method for searching the neighbourhood graph at each iteration, (3) a method for deciding which is the next node that the search will choose. In general, the larger the neighbourhood, the better. The local search is able to 'look' further away from its current solution and reduce its chance of becoming stuck in a small area of the solution space. However, some neighbourhoods may be very large and generating, evaluating and comparing lots of neighbours may itself take a long time and increase the overall time of the local search.

\section{Metaheuristics}

Metaheuristics are high-level strategies that are not related to a specific problem and can try to guide a local search through the solution space. Well-known metaheuristics include Hill Climbing, Random Restarts, Simulated Annealing, Tabu Search, Genetic Algorithms, Evolutionary Algorithms, and Constraint-based Local Search \citep{blum2003metaheuristics}. Any of these techniques can be used alone or in combination with other metaheuristics to help avoid the common pitfalls of local search.

\subsection{Hill Climbing}

Steepest-ascent hill climbing search \citep{russell2016artificial} is perhaps the simplest strategy where if the solution space is seen as a series of mountains and valleys representing areas of high and low value solutions respectively, the search traverses the landscape and only moves 'uphill' to get to the highest point. To do this, the search compares all of its available moves and chooses the one that follows the steepest ascent since the intuition is that following uphill routes will lead to the highest point. This strategy usually performs poorly as it can easily become stuck in local optima and miss the global optimum (climb a hill and miss the mountain). There are several other variants of hill climbing such as stochastic hill climbing which assigns a probability of being accepted to each neighbour that is proportional to the 'steepness' of the move - i.e. how good or bad it is. It then randomly selects a neighbour according to these probabilities so that good moves have a high probability of being selected and weaker moves have a smaller (but feasible) chance of being selected. Since non-improving moves have a chance of being selected, stochastic hill climbing can converge more slowly than steepest-descent but it can yield better results by encouraging exploration of the search space \citep{russell2016artificial}. In first-choice hill climbing, rather than generating and evaluating the full neighbourhood, it randomly generates a neighbour until it finds one that improves its current solution. This can be a useful strategy with problems that have a very large neighbourhood \citep{russell2016artificial}. Random restart hill climbing performs several hill-climbing searches starting from different, random starting solutions in the hope that even if each search gets stuck in a local optimum, enough of the solution space has been explored that one of the local optima is close to the global optimum \citep{russell2016artificial}.

\subsection{Simulated Annealing}

The main issue with hill climbing search is that it never makes a 'downhill' moves which makes the algorithm incomplete because it can get stuck in local maxima/minima. In the other extreme, 'random walk' chooses the next node completely at random from any part of the state space. While this encourages a lot of exploration and eliminates getting stuck, it is not a good approach since the search acts completely randomly with no guidance. It is therefore desirable to mix local search with random walk \citep{russell2016artificial}. Simulated Annealing \citep{kirkpatrick1983optimization} is a method inspired by annealing in metals where the substance is first melted to allow its atoms to flow freely, and the temperature is slowly lowered until it freezes. The substance spends relatively little time near its melting point and more time close to its freezing point. By cooling it in this way, its atoms are able to move around and find a low-energy state compared to quickly freezing it and inducing defects because the atoms solidified in a sub-optimal arrangement. This process has been adapted to combinatorial optimisation problems where a temperature is cooled during the search according to a cooling schedule. When the temperature is high, the probability of accepting a 'bad' move is high and the probability reduces as the temperature is cooled. This means that the tolerance for moving from a good solution to a worse solution is high to begin with (diversification) but over time, this tolerance reduces and the search focuses on improving the current solution (intensification). In other words, the search starts off more like a random walk of the solution space and transforms into a steepest-descent hill climbing.

\subsection{Tabu Search}

When traversing the solution graph, it is possible that the search will repeatedly visit the same set of solutions. When it enters this kind of cycle, the search stalls and it gets stuck in a local area of the graph. This can happen both when only accepting improving moves or using more complex strategies to accept non-improving moves. Tabu search \citep{glover1989tabu} tries to reduce this problem by using a form of short-term memory to remember recent moves and prevent them from being made again for a given amount of time. If a move is attempted while it is still 'banned', the search must find another move that is not banned. This encourages the search to visit unexplored areas of the solution space and limits getting stuck repeating the same moves. The definition of a move is important because if a move is defined too broadly, it may be encountered too often and the tabu list may stifle the search by banning common moves. Conversely, moves that are too rare will not occur often and the tabu list is redundant since the search may still get caught in a cycle. Similarly, the length of time that a move remains banned for can greatly impact the search's performance by banning too many or too few moves at once.


%quote some papers listed in the survey
%(see \citet{kolisch2001integrated} for a comprehensive survey).

%Slide 22 of local search lecture (Escaping local maxima)